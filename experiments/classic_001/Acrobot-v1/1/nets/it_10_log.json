{"min_rewards": [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0], "max_rewards": [-500.0, -500.0, -496.0, -496.0, -496.0, -496.0, -496.0, -496.0, -402.0, -314.0], "mean_rewards": [-500.0, -500.0, -499.8333333333333, -499.875, -499.9, -499.9166666666667, -499.92857142857144, -499.9375, -498.5833333333333, -496.4], "median_rewards": [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0], "nr_episodes": [8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056], "times": [1.2077162265777588, 1.086815595626831, 1.0734987258911133, 1.076181411743164, 1.059441328048706, 1.0800983905792236, 1.0615994930267334, 1.0766775608062744, 1.0494840145111084, 1.0640947818756104], "num_total_steps": [8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056]}