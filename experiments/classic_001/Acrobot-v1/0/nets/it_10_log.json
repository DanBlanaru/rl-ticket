{"min_rewards": [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0], "max_rewards": [-500.0, -500.0, -500.0, -355.0, -355.0, -355.0, -330.0, -297.0, -297.0, -232.0], "mean_rewards": [-500.0, -500.0, -500.0, -491.59375, -493.275, -494.3958333333333, -491.875, -486.890625, -486.7916666666667, -475.2168674698795], "median_rewards": [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0], "nr_episodes": [8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056], "times": [1.2231342792510986, 1.0807740688323975, 1.064225435256958, 1.0692665576934814, 1.0867149829864502, 1.076629638671875, 1.1314611434936523, 1.117680549621582, 1.0906293392181396, 1.1113324165344238], "num_total_steps": [8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056]}