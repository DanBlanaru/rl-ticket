{"min_rewards": [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0], "max_rewards": [-500.0, -500.0, -500.0, -500.0, -462.0, -462.0, -462.0, -462.0, -455.0, -363.0], "mean_rewards": [-500.0, -500.0, -500.0, -500.0, -499.05, -498.7708333333333, -498.94642857142856, -499.078125, -498.55555555555554, -496.9625], "median_rewards": [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0], "nr_episodes": [8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056], "times": [1.1878321170806885, 1.0850067138671875, 1.0998344421386719, 1.1142122745513916, 1.080613613128662, 1.0749995708465576, 1.0760173797607422, 1.0731499195098877, 1.084362268447876, 1.0702810287475586], "num_total_steps": [8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056]}