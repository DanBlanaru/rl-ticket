{"min_rewards": [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0], "max_rewards": [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -320.0], "mean_rewards": [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -497.75], "median_rewards": [-500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0, -500.0], "nr_episodes": [8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056], "times": [1.3187506198883057, 1.1614925861358643, 1.4761321544647217, 1.4096229076385498, 1.2931270599365234, 1.3429300785064697, 1.297631025314331, 1.289330244064331, 1.222987413406372, 1.2534093856811523], "num_total_steps": [8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056]}