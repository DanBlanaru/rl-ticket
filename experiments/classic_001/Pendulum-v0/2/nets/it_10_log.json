{"min_rewards": [-1693.337034, -1847.795917, -1847.795917, -1847.795917, -1847.795917, -1847.795917, -1843.104518, -1843.104518, -1843.104518, -1841.080257], "max_rewards": [-912.273376, -880.447724, -809.437694, -809.437694, -809.437694, -629.696841, -629.696841, -621.131881, -621.131881, -621.131881], "mean_rewards": [-1229.57690675, -1279.0124594249999, -1320.6797133392859, -1308.14885545, -1318.8836466354167, -1336.1750056900003, -1332.44023907, -1303.33848571, -1289.80948567, -1285.5738437500002], "median_rewards": [-1221.3108025, -1275.8965445, -1317.2913405, -1299.849839, -1282.3172555, -1362.508368, -1356.453771, -1256.135797, -1236.4135305, -1234.0612665], "nr_episodes": [8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056], "times": [1.126774549484253, 0.9991741180419922, 1.0067126750946045, 1.0090174674987793, 1.019334077835083, 1.0100085735321045, 0.9992573261260986, 1.0316007137298584, 1.0422937870025635, 1.0209364891052246], "num_total_steps": [8192, 12288, 16384, 20480, 24576, 28672, 32768, 36864, 40960, 45056]}